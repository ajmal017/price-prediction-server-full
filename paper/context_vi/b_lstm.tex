Đối với LSTM, có rất ít tham số có thể được thay đổi. Tuy nhiên ta có thể kết hợp với các lớp LSTM lại với nhau và thêm cái các lớp khác để tạo ra nhiều tham số mới. Đối với bài báo này, các siêu tham số tìm kiếm là: số lớp LSTM d, số neuron của các lớp (con số này là bội số của 32), số ngày đầu vào để có thể đưa ra dự đoán cho ngày tiếp theo. Nếu số lớp neuron quá nhiều dẫn đến việc thông tin bị phân tích quá mức, vừa mất thời gian huấn luyện, vừa cho các quả bị overfitting. Nếu quá ít, thì thông tin phân tích không đủ, kết quả đưa ra bị hạn chế về độ chính xác. Số lượng neuron cũng tương tự vậy. Ví LSTM có số ngày đầu vào là cố định nên ta phải tìm số ngày cụ thể đó. Ngoài ra trước khi cho ra kết quả, chúng tôi cho dữ liệu đi qua một lớp dropout để hạn chế tình trạng overfitting, chỉ số dropout có thể lên tới 0.7 để hạn chế việc dữ liệu giao động mạnh ảnh hưởng tới kết quả dự đoán. Việc lạm dụng dropout, luôn chèn lớp dropout vào giữa 2 lớp LSTM có thể dần đến việc mất mát thông tin, mô hình không học được gì, dẫn đến việc mô hình không quan tâm đến đầu vào, mọi kết quả đầu ra đều giống nhau. Vì vậy chúng tối chỉ chèn 1 lớp dropout vào giữa 2 lớp ẩn và lớp output.